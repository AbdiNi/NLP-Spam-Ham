{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                          documents\n",
       "0         1  Go until jurong point, crazy.. Available only ...\n",
       "1         1                      Ok lar... Joking wif u oni...\n",
       "2         0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         1  U dun say so early hor... U c already then say...\n",
       "4         1  Nah I don't think he goes to usf, he lives aro...\n",
       "5         0  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6         1  Even my brother is not like to speak with me. ...\n",
       "7         1  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8         0  WINNER!! As a valued network customer you have...\n",
       "9         0  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=[\"category\", \"documents\"])\n",
    "data['category'] = data['category'].map({'spam':0 ,'ham':1}) \n",
    "print(len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Taking a look at my documents : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build my own tokenizer\n",
    "def my_tokenizer(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate my documents : \n",
    "all_documents = \"\";\n",
    "for i in range(len(data)) : \n",
    "    all_documents += data.documents[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81528"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our doucments are composed of 81528 words\n",
    "len(my_tokenizer(all_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100260"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using nltk tokenizer\n",
    "import nltk\n",
    "len(nltk.word_tokenize(all_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18352\n"
     ]
    }
   ],
   "source": [
    "# Our documents are composed of 18352 non-duplicated words (based on my_tekonizer function)\n",
    "words = [] \n",
    "for i in (my_tokenizer(all_documents)): \n",
    "    if i not in words: \n",
    "        words.append(i) \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14009\n"
     ]
    }
   ],
   "source": [
    "# Our documents are composed of 14009 non-duplicated words (based on nltk tokenizer)\n",
    "words = [] \n",
    "for i in (nltk.word_tokenize(all_documents)): \n",
    "    if i not in words :\n",
    "        words.append(i) \n",
    "print(len(words))\n",
    "#ponctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 747 spam and 4825 ham\n"
     ]
    }
   ],
   "source": [
    "# spam and ham numbers\n",
    "Nspam = 0\n",
    "Nham = 0\n",
    "for i in range(len(data)) : \n",
    "    if (data.category[i] == 0) : \n",
    "        Nspam +=1\n",
    "    else : \n",
    "        Nham +=1\n",
    "print(\"we have \"+str(Nspam)+\" spam and \"+str(Nham)+\" ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Processing our data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = list(data[\"category\"])\n",
    "corpus = list(data[\"documents\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
    "\n",
    "-Create an instance of the CountVectorizer class.\n",
    "-Call the fit() function in order to learn a vocabulary from one or more documents.\n",
    "-Call the transform() function on one or more documents as needed to encode each as a vector.\n",
    "\n",
    "An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document.\n",
    "\n",
    "Because these vectors will contain a lot of zeros, we call them sparse. Python provides an efficient way of handling sparse vectors in the scipy.sparse package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corpus vectorizing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector.shape =  (5572, 8577)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords    \n",
    "# create the transform\n",
    "vectorizer = CountVectorizer( stop_words=stopwords.words(\"english\"))\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(corpus)\n",
    "# summarize\n",
    "#print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(corpus)\n",
    "# summarize encoded vector\n",
    "print(\"vector.shape = \",vector.shape)\n",
    "#print(type(vector))\n",
    "print(vector.toarray())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Remarque! : \n",
    "notre matrice se compose de 5572 lignes et 8577 colonnes\n",
    "-5572 lignes est le nombre de documents dans notre jeux de donn√©es\n",
    "-8577 colonnes est le nombre total des mots par lesquelles on peut former nos documents \n",
    "!! or as we said previously we only have a 18352 different words !! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Top 10 Frequent words : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8577)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec_tfid = TfidfVectorizer(stop_words=stopwords.words(\"english\"))\n",
    "\n",
    "X = vec_tfid.fit_transform(corpus)     # Learn vocabulary and idf, return document-term matrix.\n",
    "                                       # idf : inverse document frequency\n",
    "print(X.shape)\n",
    "\n",
    "feature_names = vec_tfid.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1979, 8066, 5540, ..., 3483, 5461, 1804]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array = np.array(feature_names)\n",
    "tfidf_sorting = np.argsort(X.sum(0))\n",
    "tfidf_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chef' 'venaam' 'organizer' ... 'get' 'ok' 'call']]\n"
     ]
    }
   ],
   "source": [
    "# les 10 mots les plus fr√©quents\n",
    "n = 10\n",
    "top_n = feature_array[tfidf_sorting][:n]\n",
    "print(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Partition en corpus d‚Äôapprentissage et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.997\n",
      "Test set score: 0.986\n"
     ]
    }
   ],
   "source": [
    "#subdivision into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# vector = vectorizer.transform(corpus) \n",
    "corpusTrain, corpusTest, targetTrain, targetTest = train_test_split(vector,targets, train_size=0.8 ,random_state=42)\n",
    "\n",
    "logreg = LogisticRegression().fit(corpusTrain, targetTrain)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(corpusTrain, targetTrain)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(corpusTest, targetTest)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques pr√©dictions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tableau de pr√©dictions ###\n",
      "[1 1 1 ... 1 1 1]\n",
      "**** some predictions for verification ***\n",
      "[1]\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(corpusTest)\n",
    "print(\"### tableau de pr√©dictions ###\")\n",
    "print(y_pred)\n",
    "print(\"**** some predictions for verification ***\")\n",
    "print(logreg.predict(vector[0]))\n",
    "print(logreg.predict(vector[1]))\n",
    "print(logreg.predict(vector[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  19]\n",
      " [  2 966]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Matrice de confusion\n",
    "conf = confusion_matrix(targetTest, y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "r√©sultat = 0 et le modele pr√©dit 0 = 128  \n",
    "r√©sultat = 0 et le modele pr√©dit 1 = 19  \n",
    "r√©sultat = 1 et le modele pr√©dit 0 = 2  \n",
    "r√©sultat = 1 et le mod√®le pr√©dit 1 = 966 \n",
    "\n",
    "Bonne pr√©dictions = 128+966 = 1094\n",
    "Mauvaise pr√©dictions = 2+19 = 21\n",
    "score = 1094/1115 = 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  19]\n",
      " [  2 966]]\n",
      "recall =  0.8707482993197279\n",
      "precison = 0.9846153846153847\n",
      "F1_score =  0.9241877256317689\n",
      "accuracy =  0.9811659192825112\n"
     ]
    }
   ],
   "source": [
    "#import the metrics class for the performance measurement\n",
    "from sklearn import metrics\n",
    "#confusion matrix\n",
    "mcTest = metrics.confusion_matrix(targetTest, y_pred)\n",
    "print(mcTest)\n",
    "#recall\n",
    "print(\"recall = \",metrics.recall_score(targetTest,y_pred,pos_label=0))\n",
    "#precision\n",
    "print(\"precison =\", metrics.precision_score(targetTest,y_pred,pos_label=0))\n",
    "#F1-Score\n",
    "print(\"F1_score = \", metrics.f1_score(targetTest,y_pred,pos_label=0))\n",
    "#accuracy rate\n",
    "print(\"accuracy = \",metrics.accuracy_score(targetTest, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- what about other models ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf4 = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2),('svc', clf3)],voting='soft', weights=[2, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=4)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=7)),\n",
       "                             ('svc', SVC(gamma=0.1, probability=True))],\n",
       "                 voting='soft', weights=[2, 1, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(corpusTrain, targetTrain)\n",
    "clf2.fit(corpusTrain, targetTrain)\n",
    "clf3.fit(corpusTrain, targetTrain)\n",
    "clf4.fit(corpusTrain, targetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier score: 0.928\n",
      "KNeighborsClassifier score: 0.915\n",
      "SVC Training  score: 0.996\n",
      "VotingClassifier score: 0.973\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTreeClassifier score: {:.3f}\".format(clf1.score(corpusTrain, targetTrain)))\n",
    "print(\"KNeighborsClassifier score: {:.3f}\".format(clf2.score(corpusTrain, targetTrain)))\n",
    "print(\"SVC Training  score: {:.3f}\".format(clf3.score(corpusTrain, targetTrain)))\n",
    "print(\"VotingClassifier score: {:.3f}\".format(clf4.score(corpusTrain, targetTrain)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Cross-validation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99283154, 0.97670251, 0.98384201, 0.98922801, 0.98025135,\n",
       "       0.98204668, 0.98563734, 0.98025135, 0.98025135, 0.98384201])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, vector,targets, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, vector, targets, scoring=scoring)\n",
    "sorted(scores.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93948187, 0.93948187, 0.93572348, 0.9295302 , 0.94862816])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['fit_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28440189, 0.30109501, 0.2601397 , 0.25932455, 0.26426649])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['score_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98707563, 0.98707563, 0.98651891, 0.98935091, 0.98497835])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_precision_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93948187, 0.93948187, 0.93572348, 0.9295302 , 0.94862816])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_recall_macro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with ShuffleSplit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9432624113475176, 0.9198606271777003, 0.9400630914826498, 0.9520295202952028, 0.9416058394160584, 0.9160839160839161, 0.929368029739777, 0.9278350515463918, 0.9019607843137255, 0.9266666666666666]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rs = ShuffleSplit(n_splits=10, test_size=.2, random_state=42)\n",
    "rs.get_n_splits(vector)\n",
    "\n",
    "targets = np.array(targets)\n",
    "\n",
    "scores =[]\n",
    "for train_index, test_index in rs.split(vector):\n",
    "    X_train =  vector[train_index]\n",
    "    X_test = vector[test_index]\n",
    "    y_train = targets[train_index]\n",
    "    y_test = targets[test_index]\n",
    "    logreg = LogisticRegression().fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    score = f1_score(y_test,y_pred,pos_label=0)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(scores)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
